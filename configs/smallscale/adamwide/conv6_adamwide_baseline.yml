# Architecture
arch: Conv6Wide

# ===== Dataset ===== #
data: /mnt
set: CIFAR10
name: conv6_adamwide_baseline

# ===== Learning Rate Policy ======== #
optimizer: adam
lr: 0.0003

# ===== Network training config ===== #
epochs: 100
batch_size: 60

# ===== Sparsity =========== #
conv_type: DenseConv
bn_type: NonAffineBatchNorm

# ===== Hardware setup ===== #
workers: 4